{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path,num_images,xdim,ydim):\n",
    "    images = []\n",
    "    all_paths = os.listdir(path)\n",
    "    mini_set = all_paths[:num_images]\n",
    "    for i in mini_set:\n",
    "        file = path+\"/\"+i\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image,(xdim,ydim))\n",
    "        images.append(image)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "#function to convert rgb to lab \n",
    "def rgb_to_lab(images):\n",
    "    lab_images = []\n",
    "    for i in images:\n",
    "        lab_image= cv2.cvtColor(i, cv2.COLOR_RGB2LAB)\n",
    "        lab_images.append(lab_image)\n",
    "\n",
    "    return lab_images\n",
    "\n",
    "def lab_to_rgb(images):\n",
    "    rgb_images = []\n",
    "    for i in images:\n",
    "        lab_image= cv2.cvtColor(i, cv2.COLOR_LAB2RGB)\n",
    "        lab_images.append(lab_image)\n",
    "\n",
    "#function to extract the l channels and ab for training\n",
    "def extract_channels(lab_images):\n",
    "    l_channels = []\n",
    "    a_channels = []\n",
    "    b_channels = []\n",
    "    for i in lab_images:\n",
    "        l,a,b = cv2.split(i)\n",
    "        l_channels.append(l)\n",
    "        a_channels.append(a)\n",
    "        b_channels.append(b)\n",
    "\n",
    "    return np.array(l_channels), np.array(a_channels), np.array(b_channels)\n",
    "\n",
    "#function to create train and test data\n",
    "def create_train_data(l,a,b):\n",
    "    train_data = []\n",
    "    for i in l:\n",
    "        train_data.append(np.array(i,dtype= 'float32'))\n",
    "    train_labels_a = []\n",
    "    train_labels_b = []\n",
    "    for i in a:\n",
    "        train_labels_a.append(np.array(i.flatten(),dtype='float32'))\n",
    "    for i in b:\n",
    "        train_labels_b.append(np.array(i.flatten(),dtype='float32'))\n",
    "    train_labels = []\n",
    "    for i,j in zip(train_labels_a,train_labels_b):\n",
    "        train_labels.append(np.concatenate((i,j),axis = 0))\n",
    "    \n",
    "    return train_data, train_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Arghyadeep/Desktop/image colorization/new process/train2017\"  #path needs to be changed\n",
    "num_images = 50000   #this number can be changed according to number of image data in train folder\n",
    "#converting all images to 128*128\n",
    "x_dim = 128\n",
    "y_dim = 128\n",
    "images = read_images(path,num_images,x_dim,y_dim) #read images\n",
    "lab_images = rgb_to_lab(images) #convert rgb to lab space images\n",
    "l,a,b = extract_channels(lab_images) #separate l, a and b channels\n",
    "train_data, train_labels = create_train_data(l,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(train_data,(num_images,x_dim,y_dim,1))\n",
    "train_data.shape[3]\n",
    "train_labels = np.reshape(train_labels,(num_images,128*128*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D as Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 16)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 59, 59, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 59, 59, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             2129920   \n",
      "=================================================================\n",
      "Total params: 2,214,960\n",
      "Trainable params: 2,214,736\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_cols = 128\n",
    "img_rows = 128\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train_data = train_data.reshape(train_data.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    train_data = train_data.reshape(train_data.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (4, 4),activation='relu',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(train_labels.shape[1], activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 16068.8980 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 16048.0593 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 16015.3425 - acc: 0.0000e+00A: 0s - loss: 16022.8945 - acc: 0.0000e+\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 15971.3172 - acc: 0.0000e+00A: 2s - loss: 15919.3743 - ac\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 15918.3530 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 15855.9120 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 15783.6992 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 15704.1982 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 15618.1313 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 15524.3023 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 15422.5380 - acc: 0.0000e+00A: 2s - loss: 15362.4998 - acc\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 15312.5678 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 15196.6382 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 15071.9503 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 14938.8261 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 14797.6743 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 14650.8560 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 14496.5696 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 14334.6751 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 14165.3683 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 13989.5081 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13806.8122 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13618.0259 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13423.8601 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13222.5770 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13015.5246 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 12802.5629 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 12583.9250 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 12359.5797 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 12131.2244 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 11898.7338 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 11659.8641 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 11415.8938 - acc: 0.0000e+00A: 0s - loss: 11476.9276 - acc: 0.000\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 11169.8189 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 10917.7165 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 10662.7217 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 10404.8069 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 10142.1964 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9877.9181 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9610.2580 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 9340.5713 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 9068.6479 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8793.7417 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 8518.9194 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 8241.4538 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 7964.3299 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 7685.2537 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 7407.6114 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 7129.2140 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 6850.3611 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 6572.4294 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 6295.1218 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 6020.7598 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 5746.7629 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 5474.6337 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 5205.1975 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 4939.3857 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 4675.1860 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 4415.3539 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 4159.4127 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 3907.5152 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 3660.2940 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 3417.9194 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 3182.1790 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 2951.4721 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 2727.1793 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 2509.3163 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 2301.2785 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 2096.9127 - acc: 0.0000e+00: 1s - loss: 2166.7773\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1901.4238 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1715.4224 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1537.2166 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 1368.9327 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 1209.5396 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1061.4105 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 923.0001 - acc: 0.0000e+00\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 5ms/step - loss: 795.3498 - acc: 0.0000e+00A: 1s - loss: 826.2000 - acc: 0.0\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 680.1198 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 575.3607 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 484.7620 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 403.0434 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 335.7539 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 279.0752 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 236.3241 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 205.9693 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 186.1573 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 174.6217 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 170.0967 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 166.0257 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 162.7965 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 162.2800 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 159.0814 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 156.6054 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 154.2947 - acc: 0.0000e+00A: 0s - loss: 161.9066 - acc: 0.00\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 152.4651 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 151.5301 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 149.0779 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 149.4098 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 147.1567 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 146.6683 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ed3afc550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 100\n",
    "model.fit(train_data, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Arghyadeep/Desktop/image colorization/new process/val2017\"\n",
    "num_images = 100\n",
    "#converting all images to 128*128\n",
    "x_dim = 128\n",
    "y_dim = 128\n",
    "images = read_images(path,num_images,x_dim,y_dim) #read images\n",
    "lab_images = rgb_to_lab(images) #convert rgb to lab space images\n",
    "l,a,b = extract_channels(lab_images) #separate l, a and b channels\n",
    "train_data, train_labels = create_train_data(l,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 50 # choose an image to run test on\n",
    "tr = np.reshape(train_data[index],(1,128,128,1)) \n",
    "p = model.predict(tr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(p[0])\n",
    "length = len(p[0])\n",
    "x1 = x[:int(length/2)] #divide predicted a and b channels to equal halves to get a and b channels\n",
    "x2 = x[int(length/2):]\n",
    "\n",
    "x1 = np.array(np.reshape(x1,(x_dim,y_dim)),dtype = 'uint8')\n",
    "x2 = np.array(np.reshape(x2,(x_dim,y_dim)),dtype = 'uint8')\n",
    "#x1 = np.reshape(x1,(64,64))\n",
    "#x2 = np.reshape(x2,(64,64))\n",
    "t = np.array(np.reshape(tr,(x_dim,y_dim)),dtype = 'uint8')\n",
    "pred = cv2.merge((t,x1,x2)) #merge L channel with a and b channels to find colorized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pred.pkl\",pred) #this pickle is used to plot the image\n",
    "np.save(\"bnw.pkl\",t) #this pickle is used to plot the L channel image(grayscale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
